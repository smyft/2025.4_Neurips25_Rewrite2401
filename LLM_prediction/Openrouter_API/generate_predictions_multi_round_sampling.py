import json
import os
import copy
import random
from datetime import datetime
from LLM_prediction.Openrouter_API.LLM_interface import LLM_interface

def extract_probability_from_json_format_response(llm_response):
    """
    Extracts the probability of stock price rise from LLM's response.

    Parameters:
    llm_response (str): The response generated by LLM.

    Returns:
    float: The extracted probability.
    """
    try:
        start = llm_response.find('{')
        end = llm_response.rfind('}')
        if start == -1 or end == -1 or start >= end:
            return ["Invalid JSON", "Invalid JSON", "Invalid JSON"]
            
        response_dict = json.loads(llm_response[start:end+1])
        
        required_fields = ["probability_of_stock_price_rise", "probability_of_stock_price_fall", "reasoning"]
        for field in required_fields:
            if field not in response_dict:
                return [f"Missing {field}", f"Missing {field}", f"Missing {field}"]
                
        # rise = int(response_dict["probability_of_stock_price_rise"]) / 100
        # fall = int(response_dict["probability_of_stock_price_fall"]) / 100
        rise = float(response_dict["probability_of_stock_price_rise"])
        fall = float(response_dict["probability_of_stock_price_fall"])
        return [rise, fall, response_dict["reasoning"]]
        
    except (json.JSONDecodeError, ValueError, TypeError, KeyError) as e:
        return ["Parse error", "Parse error", "Parse error"]

def get_multi_round_prediction(date, headline, content, company_symbol, company_name, model_name, current_time, sample_idx, round_number, previous_predictions=None, **kwargs):
    base_info = (
        "Analyze this financial news and estimate stock price movement probabilities.\n"
        f"Company: {company_name} ({company_symbol})\n"
        f"News Headline: {headline}\n"
        f"News Content: {content}"
    )

    response_format = (
        "Now give your prediction about the probability of the stock price of the relevant company rising or falling. "
        "Format your response in JSON format and include the following information as follows: \n"
        "{ \n"
        '"reasoning": "[Summarize your analysis and reasoning process here]", \n'
        '"company_name": "[Company Name indicating the name of the company]", \n'
        '"company_symbol": "[Company Symbol indicating the stock symbol of the company]", \n'
        '"news_headline": "[News Headline indicating the provided financial news headline]", \n'
        '"probability_of_stock_price_rise": [The estimated probability (a number between 0 and 1) that the stock price will rise due to this news], \n'
        '"probability_of_stock_price_fall": [The estimated probability (a number between 0 and 1) that the stock price will fall due to this news], \n'
        "} \n"
        "Do not generate output that isn't in properly formatted JSON."
    )

    if previous_predictions:
        history_result = ""
        for idx, single_round_results in enumerate(previous_predictions):
            history_result += (
                f"Round: {idx}\n"
            )
            for round_dict in single_round_results:
                history_result += (
                    f"Model: {round_dict['model_name']}, "
                    f"Prediction of stock price rising: {round_dict['rise_prediction']}, "
                    f"Prediction of stock price falling: {round_dict['fall_prediction']}, "
                    f"Reasoning: {round_dict['reasoning']}\n"
                )
                
        prediction_history = (
            "Next I will provide you some predictions of stock price movement probabilities and the corresponding analysis by others in the previous rounds.\n"
            "Note that others' predictions may indicate that they have some other information about the stock price. "
            "A high prediction may indicate that they have some positive information about the stock, while a low prediction may indicate that they have some megative information about the stock.\n"
            "Also note that there are multiple rounds of precitions, demonstrating the trend of others' beliefs.\n"
            "Please take these information into consideration when prediction the stock price movement probabilities.\n"
            "Previous predictions:\n"
            f"{history_result}"
        )
    else:
        prediction_history = ""

    user_message = (
        f"{base_info}\n\n"
        f"{prediction_history}\n\n"
        f"{response_format}"
    )

    model_name_for_path = model_name
    if '/' in model_name:
        model_name_for_path = "-".join(model_name.split('/'))
    os.makedirs(f'log/Multi_Round_Sampling/{current_time}/Date_{date}/Sample_{sample_idx}/Round_{round_number}', exist_ok=True)
    log_file_path = f'log/Multi_Round_Sampling/{current_time}/Date_{date}/Sample_{sample_idx}/Round_{round_number}/{model_name_for_path}.json'
    dialogue_history = [{"role": "user", "content": user_message}]

    print("------")
    print(f"model_name_for_path: {model_name_for_path}")
    dialogue_content = LLM_interface(
        model=model_name,
        dialogue_history=dialogue_history,
        log_file_path=log_file_path,
        **kwargs
    )
    print("------")

    if dialogue_content is None:
        return ["Missing dialogue content", "Missing dialogue content", "Missing dialogue content"]

    dialogue_content = dialogue_content["dialogue_history"]
    last_assistant_content = None
    for msg in reversed(dialogue_content):
        if msg.get("role") == "assistant":
            last_assistant_content = msg.get("content")
            break

    if last_assistant_content is None:
        print(dialogue_content)
        return ["Missing assistant response", "Missing assistant response", "Missing assistant response"]

    prediction = extract_probability_from_json_format_response(last_assistant_content)

    return prediction

def run_multi_round_analysis():
    # current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    current_time = "2025-05-05_17-14-05"
    # data_file_path = './data/financial_news_headlines/origin_data_20samples.json'
    start_date = '2025-01-01'
    end_date = '2025-01-31'
    data_file_path = f'data/financial_news_headlines/origin_data_{start_date}_{end_date}_AAPL_split.json'
    
    with open(data_file_path, 'r') as f:
        data = json.load(f)
    
    model_list = ['openai/gpt-4o-mini', 'google/gemini-2.0-flash-001', 'google/gemini-flash-1.5', 'deepseek/deepseek-chat-v3-0324',
                  'meta-llama/llama-4-scout', 'meta-llama/llama-3.3-70b-instruct', 'qwen/qwen-turbo']
    
    num_rounds = 5
    num_sampling = 10
    file_part_number = 8
    start_date = "2025-01-08"
    end_date = "2025-01-01"
    
    prediction_results = []
    for company_id, company_symbol_dict in enumerate(data):
        company_symbol = company_symbol_dict["company_symbol"]
        company_name = company_symbol_dict["company_name"]

        print("******")
        print(f"Processing Company: {company_symbol} ({company_name})")

        results_dict = {}
        results_dict["company_id"] = company_id
        results_dict["company_symbol"] = company_symbol
        results_dict["company_name"] = company_name
        
        results_dict["predictions"] = []

        for date_dict in company_symbol_dict["financial_news"]:
            date = date_dict["date"]
            news = date_dict["news"]

            if date > start_date:
                continue
            if date <= end_date:
                break

            print(f"\nProcessing Date: {date}")

            sample_result = []

            for sample_idx in range(num_sampling):
                print(f"Sample {sample_idx}")

                sampled_news = [random.choice(news) for _ in model_list]

                all_rounds = []
                prev_predictions = None
        
                for round_idx in range(num_rounds):
                    print(f"Round {round_idx}")
            
                    single_round_results = []
                    for model_idx, model_name in enumerate(model_list):
                        headline = sampled_news[model_idx]["title"]
                        content = sampled_news[model_idx]["content"]
                
                        round_dict = {}
                        pred_rise, pred_fall, reasoning = get_multi_round_prediction(
                            date=date,
                            headline=headline,
                            content=content,
                            company_symbol=company_symbol,
                            company_name=company_name,
                            model_name=model_name,
                            current_time=current_time,
                            sample_idx=sample_idx,
                            round_number=round_idx,
                            previous_predictions=prev_predictions,
                            logprobs=False,
                            temperature=1
                        )
                
                        round_dict["model_name"] = model_name
                        round_dict["round"] = round_idx
                        round_dict["headline"] = headline
                        round_dict["content"] = content
                        if isinstance(pred_rise, float):
                            round_dict["rise_prediction"] = pred_rise
                            round_dict["fall_prediction"] = pred_fall
                            round_dict["reasoning"] = reasoning
                        else:
                            round_dict["rise_prediction"] = -1
                            round_dict["fall_prediction"] = -1
                            round_dict["reasoning"] = f"Fail to give a prediction. Error Reason: {reasoning}"
                        single_round_results.append(round_dict)
            
                    all_rounds.append(copy.deepcopy(single_round_results))
                    prev_predictions = all_rounds

                sample_result.append({"Sample": sample_idx, "predictions": all_rounds})

            results_dict["predictions"].append({"date": date, "predictions": sample_result})
        
        prediction_results.append(results_dict)
        print("******")

    os.makedirs(f"./results/LLM_predictions/Multi_Round_Sampling", exist_ok=True)
    results_file_path = f"./results/LLM_predictions/Multi_Round_Sampling/{current_time}_Part{file_part_number}.json"
    with open(results_file_path, 'w') as f:
        json.dump(prediction_results, f)

if __name__ == "__main__":
    run_multi_round_analysis()
